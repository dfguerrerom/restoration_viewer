{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "objective-survival",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "\n",
    "import ipyvuetify as v\n",
    "from traitlets import (\n",
    "    Unicode, observe, directional_link, \n",
    "    List, Int, Bool, CFloat, link, Any\n",
    ")\n",
    "from ipyleaflet import GeoJSON, TileLayer\n",
    "from haversine import haversine\n",
    "\n",
    "from shapely_geojson import dumps\n",
    "import json\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bulgarian-machinery",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sepal_ui.mapping import mapping as m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "clean-stand",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99c257e91c1d44f9a3576be85c181676",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Styles()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e5b3b5436e54adca86b89b3f7d6126f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ResizeTrigger()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "993bd739335b49c7b62dc00d64a9b064",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='\\n<style>\\nbody.jp-Notebook, \\ndiv.jp-Cell,\\ndiv.jp-OutputArea-output {\\n\\n    margin: 0 !importan…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from component.scripts.scripts import *\n",
    "from component.widget.custom_widgets import *\n",
    "from component.frontend.styles import *\n",
    "from component.message import cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "computational-convert",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import geopandas as gpd\n",
    "from traitlets import Unicode, link, observe\n",
    "import ipyvuetify as v \n",
    "import sepal_ui.sepalwidgets as sw\n",
    "from component.widget.custom_widgets import *\n",
    "\n",
    "class AOI(v.Layout):\n",
    "    \n",
    "    shapefile = Unicode('').tag(sync=True)\n",
    "    \n",
    "    def __init__(self, statebar=None, **kwargs):\n",
    "    \n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        self.gdf = None\n",
    "        \n",
    "        # Parameters\n",
    "        self.out_path = Path('')\n",
    "        self.json_path = None\n",
    "        \n",
    "        # Widgets\n",
    "        self.shape_input = sw.FileInput(['.shp'], os.getcwd())\n",
    "        \n",
    "        self.w_state_bar = StateBar(done=True) if not statebar else statebar\n",
    "        \n",
    "        # Link behaviours \n",
    "        \n",
    "        link((self.shape_input, 'file'), (self, 'shapefile'))\n",
    "        \n",
    "        # View\n",
    "        \n",
    "        self.children=[\n",
    "            v.Layout(row=True, children=[\n",
    "                self.shape_input,\n",
    "            ])\n",
    "        ]\n",
    "        \n",
    "        # Add a statebar if there is not provided an external one\n",
    "        if not statebar: self.children = self.children + [self.w_state_bar]\n",
    "\n",
    "    @observe('shapefile')\n",
    "    def shape_to_geojson(self, change):\n",
    "        \"\"\" Converts shapefile into Json file\"\"\"\n",
    "        \n",
    "        shp_file_path = Path(self.shapefile)\n",
    "        if shp_file_path.suffix == '.shp':\n",
    "\n",
    "            self.gdf = gpd.read_file(str(shp_file_path))\n",
    "            self.gdf = self.gdf.to_crs(\"EPSG:4326\")\n",
    "            \n",
    "            self.json_path = shp_file_path.parent/f'{shp_file_path.stem}.geojson'\n",
    "            \n",
    "            if not self.json_path.exists():\n",
    "                self.w_state_bar.add_msg('Converting shape to GeoJSON', done=False)\n",
    "                self.gdf.to_file(str(self.json_path), driver='GeoJSON')\n",
    "                self.w_state_bar.add_msg('Done', done=True)\n",
    "            else:\n",
    "                self.w_state_bar.add_msg('Geojson file already created', done=True)\n",
    "                \n",
    "    def get_ipyleaflet_geojson(self):\n",
    "        \"\"\"Returns GeoJSON ipyleaflet object from Json file\"\"\"\n",
    "        \n",
    "        if self.json_path:\n",
    "            self.w_state_bar.add_msg('Converting shape to GeoJSON', done=False)\n",
    "            with open(self.json_path) as f:\n",
    "                data = json.load(f)        \n",
    "                ipygeojson = GeoJSON(\n",
    "                    data=data,\n",
    "                    name=self.json_path.stem, \n",
    "                    style={'color': 'green', 'fillOpacity': 0, 'weight': 3})\n",
    "\n",
    "            self.w_state_bar.add_msg('Done', done=True)\n",
    "        \n",
    "            return ipygeojson\n",
    "        else:\n",
    "            self.w_state_bar.add_msg('There is not a shapefile selected.', done=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abstract-storage",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlanetTile(v.Layout):\n",
    "    \n",
    "    def __init__(self, *args, **kwargs)\n",
    "    \n",
    "        self.row = True\n",
    "        \n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "        self.api_key = 'e74724542185443697ad280f680859d0'\n",
    "        self.valid_planet = False\n",
    "        self.client = None\n",
    "        \n",
    "        self.w_api_key = PasswordField(\n",
    "            v_model=self.api_key\n",
    "        )\n",
    "        \n",
    "        self.w_api_btn = sw.Btn('Validate ', small=True,)\n",
    "        \n",
    "        w_api_key = v.Flex(class_='d-flex align-center mb-2', \n",
    "               row=True, \n",
    "               children =[self.w_api_key, self.w_api_btn]\n",
    "        )\n",
    "        \n",
    "        self.children = [\n",
    "            w_api_key,\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hundred-gathering",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parameters(v.Layout):\n",
    "    \n",
    "    def __init__(self, *args, **kwargs)\n",
    "    \n",
    "        self.row = True\n",
    "        \n",
    "        super().__init__(*args, **kwargs)\n",
    "    \n",
    "        self.w_sources = v.Autocomplete(\n",
    "            items=['Planet', 'Landsat', 'Sentinel'], \n",
    "            label='Imagery source',\n",
    "            chips=True, \n",
    "            clearable=True, \n",
    "            deletable_chips=True, \n",
    "            multiple=True\n",
    "        )\n",
    "        \n",
    "        self.w_years = v.RangeSlider(\n",
    "            tick_labels=list(str(x) for x in range(2010, 2021+1, 1)),\n",
    "            v_model = ['2017', '2018'],\n",
    "            min=\"2010\",\n",
    "            max=\"2021\",\n",
    "            ticks=\"always\",\n",
    "            tick_size=\"1\"\n",
    "        )\n",
    "        \n",
    "        self.w_month = v.Slider(ticks=\"always\", tick_size=\"1\", min=1, max=12, step=1, class_='pa-10',\n",
    "                 track_color='primary', color='primary', thumb_color='grey', v_model=6,\n",
    "                 tick_labels=['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n",
    "                              'Jul', 'Ago', 'Sep', 'Oct', 'Nov', 'Dec'])\n",
    "        \n",
    "\n",
    "        \n",
    "        self.w_aoi = AOI(self.w_state_bar)\n",
    "        \n",
    "        self.w_api_btn.on_event('click', self.validate_api_event)\n",
    "        self.w_nav_feats.observe(self.zoom_to_feature, 'v_model')\n",
    "        \n",
    "        self.children = [\n",
    "            w_api_key,\n",
    "            \n",
    "        ]\n",
    "        \n",
    "    def validate_api_event(self, widget, change, data):\n",
    "        \n",
    "        self.api_key = self.w_api_key.v_model\n",
    "        \n",
    "        planet_key = PlanetKey(self.api_key)\n",
    "        self.client = planet_key.client()\n",
    "        \n",
    "        self.valid_planet = planet_key.is_active()\n",
    "        \n",
    "#         if self.valid_planet:\n",
    "#             self.w_api_alert.add_msg(cm.ui.success_api.msg, cm.ui.success_api.type)\n",
    "#             self._toggle_planet_setts(on=True)\n",
    "#         else:\n",
    "#             self.w_api_alert.add_msg(cm.ui.fail_api.msg, cm.ui.fail_api.type)\n",
    "#             self._toggle_planet_setts(on=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adopted-fancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiMap(v.Container):\n",
    "    \n",
    "    center = List([4,-74])\n",
    "    zoom = CFloat(5)\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        \n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        self.maps = {}\n",
    "\n",
    "        self.map_count = 0\n",
    "        self.w_state_bar = StateBar(done=True)\n",
    "        self.w_nav_feats = DynamicSelect(label='Features')\n",
    "        \n",
    "        self.btn_get_maps = v.Btn(children=['Get Maps'],)\n",
    "        \n",
    "        # Events\n",
    "        self.btn_get_maps.on_event('click', self.get_maps_widget)\n",
    "\n",
    "        \n",
    "        # View\n",
    "        \n",
    "        self.children=[\n",
    "            self.btn_get_maps\n",
    "        ]\n",
    "\n",
    "        self.children = self.children_opts\n",
    "\n",
    "        \n",
    "    def _get_items(self):\n",
    "        \n",
    "        # Get json geometry from selected feature\n",
    "        geom = json.loads(dumps(self.w_aoi.gdf.iloc[self.w_nav_feats.v_model].geometry.buffer(0.001, cap_style=3)))\n",
    "        \n",
    "        items = []\n",
    "        # Get items for each year-month\n",
    "        for year in range(self.w_years.v_model[0], self.w_years.v_model[1]+1):\n",
    "            \n",
    "            ini_date = datetime.datetime(year, self.w_month.v_model, 1)\n",
    "            end_date = datetime.datetime(year, self.w_month.v_model, calendar.monthrange(year,self.w_month.v_model)[1])\n",
    "            \n",
    "            req = build_request(geom, ini_date, end_date, cloud_cover=.15)\n",
    "            items.append(get_items('Planet', req, self.client))\n",
    "        \n",
    "        return items\n",
    "    \n",
    "    def _prioritize_items(self):\n",
    "                \n",
    "        dates = self._get_items()\n",
    "        print(len(dates))\n",
    "        \n",
    "        items_date = []\n",
    "        for items in dates:\n",
    "            it = [(item['properties']['item_type'], \n",
    "                      item['id'],\n",
    "                      pd.to_datetime(item['properties']['acquired']).strftime('%Y-%m-%d-%H:%M')\n",
    "                     ) for item in items[1]]\n",
    "        \n",
    "            items_df = pd.DataFrame(data=it, columns=['item_type', 'id', 'date'])\n",
    "            items_df.sort_values(by=['item_type'])\n",
    "            items_df.drop_duplicates(subset=['date', 'id'])\n",
    "        \n",
    "            # If more than one day is selected, get one image per day.\n",
    "\n",
    "            items_df.date = pd.to_datetime(items_df.date)\n",
    "            items_df = items_df.groupby(\n",
    "                [items_df.date.dt.year, items_df.date.dt.day]\n",
    "            ).nth(1).reset_index(drop=True)\n",
    "\n",
    "            items_df = items_df.head(1)\n",
    "\n",
    "            items_date.append(items_df)\n",
    "        \n",
    "        return items_date\n",
    "\n",
    "    def add_layers(self):\n",
    "        \"\"\"Search planet imagery and add them to every map_\"\"\"\n",
    "        \n",
    "        # Validate whether Planet API Key is valid,\n",
    "        # and if there is already selected coordinates.\n",
    "        \n",
    "        items_df = self._prioritize_items()\n",
    "        print(items_df)\n",
    "        \n",
    "        for map_, items_df in zip(self.maps.values(), items_df):\n",
    "\n",
    "            # remove all previous loaded assets\n",
    "            remove_layers_if(map_, 'attribution', 'Planet')\n",
    "\n",
    "            for i, row in items_df.iterrows():\n",
    "                layer = TileLayer(\n",
    "                    url=f'https://tiles0.planet.com/data/v1/{row.item_type}/{row.id}/{{z}}/{{x}}/{{y}}.png?api_key={self.api_key}',\n",
    "                    name=f'{row.item_type}, {row.date}',\n",
    "                    attribution='Planet'\n",
    "                )\n",
    "                layer.__setattr__('_metadata', {'type':row.item_type, 'id':row.id})\n",
    "                if row.id not in [layer._metadata['id'] for layer in map_.layers if hasattr(layer, '_metadata')]:\n",
    "                    map_+layer\n",
    "    \n",
    "    def zoom_to_feature(self, change, zoom_out=1):\n",
    "\n",
    "        \"\"\"Get coordinates for the current feature and zoom it to maps\"\"\"\n",
    "\n",
    "        geom = self.w_aoi.gdf.loc[change['new']].geometry\n",
    "\n",
    "        min_lon, min_lat, max_lon, max_lat = geom.bounds\n",
    "        lon, lat = geom.centroid.x, geom.centroid.y\n",
    "\n",
    "        tl = (min_lon, max_lat)\n",
    "        bl = (min_lon, min_lat)\n",
    "        tr = (max_lon, max_lat)\n",
    "        br = (max_lon, min_lat)\n",
    "\n",
    "        maxsize = max(haversine(tl, br), haversine(bl, tr))\n",
    "        lg = 40075 # number of displayed km at zoom 1\n",
    "        zoom = 1\n",
    "        while lg > maxsize:\n",
    "            zoom += 1\n",
    "            lg /= 2\n",
    "\n",
    "        if zoom_out > zoom:\n",
    "            zoom_out = zoom - 1\n",
    "\n",
    "        self.zoom = zoom-zoom_out\n",
    "        self.center = (lat, lon)\n",
    "        \n",
    "        self.add_layers()\n",
    "                \n",
    "    def _get_loading_maps_layout(self, max_cols, complete_rows, tails):\n",
    "        \"\"\"Get loading layout, while maps are ready to display\"\"\"\n",
    "        \n",
    "        w_loading_maps = v.Content(\n",
    "            _metadata={'type':'loading_map_tiles'},\n",
    "            children= \n",
    "                [v.Row(\n",
    "                    children=[\n",
    "                        v.Col(\n",
    "                            children=[v.SkeletonLoader(type=\"image\")]\n",
    "                        )for col in range(max_cols)]\n",
    "                ) for row in range(complete_rows)] + \\\n",
    "                [v.Row(\n",
    "                    children=[\n",
    "                        v.Col(\n",
    "                            children=[v.SkeletonLoader(type=\"image\")]\n",
    "                        ) for tail in range(tails)\n",
    "                    ]\n",
    "                )]\n",
    "        )\n",
    "        \n",
    "        return w_loading_maps\n",
    "    \n",
    "    def _add_features_to_map(self):\n",
    "        \n",
    "        features = self.w_aoi.get_ipyleaflet_geojson()\n",
    "        self.w_nav_feats.items = self.w_aoi.gdf.index.to_list()\n",
    "        \n",
    "        for map_ in self.maps.values():\n",
    "            map_+features\n",
    "        \n",
    "    def get_maps_layout(self):\n",
    "        \"\"\"Instantiate SepalMaps in a grid\"\"\"\n",
    "        \n",
    "        # Get the number of maps to be displayed\n",
    "        start, end = self.w_years.v_model\n",
    "        max_cols = 4\n",
    "        n_maps = len(range(start,end+1,1))\n",
    "        complete_rows = math.floor(n_maps/max_cols)\n",
    "        tails = n_maps%max_cols\n",
    "        \n",
    "        # Get childrens with metadata\n",
    "        childs = [(i, ch._metadata['type']) for i, ch in enumerate(self.children) if ch._metadata]\n",
    "        tiles = []\n",
    "        if childs:\n",
    "            idxs, tiles = zip(*childs)\n",
    "        \n",
    "        if 'map_tiles' not in tiles:\n",
    "            # If not maps in view, display loading_tiles\n",
    "            self.children = self.children + [self._get_loading_maps_layout(max_cols, complete_rows, tails)]\n",
    "            \n",
    "        else:\n",
    "            self.children = [chd for idx, chd in enumerate(self.children) if idx not in idxs] + \\\n",
    "            [self._get_loading_maps_layout(max_cols, complete_rows, tails)]\n",
    "        \n",
    "        self.w_state_bar.add_msg('Loading maps...', done=False)\n",
    "        \n",
    "        self.w_maps = v.Content(\n",
    "            _metadata={'type' : 'map_tiles'},\n",
    "            children=[\n",
    "                v.Row(\n",
    "                    children=[\n",
    "                        v.Col(\n",
    "                            children=[self.create_map()]\n",
    "                    ) for col in range(max_cols)]\n",
    "            ) for row in range(complete_rows)] + \\\n",
    "            [v.Row(\n",
    "                 children=[\n",
    "                     v.Col(\n",
    "                         children=[self.create_map()]\n",
    "                    ) for tail in range(tails)\n",
    "                ]\n",
    "            )]\n",
    "                \n",
    "        )\n",
    "        \n",
    "        self._add_features_to_map()\n",
    "        \n",
    "        \n",
    "        # Replace loading squares with loaded maps\n",
    "        self.children = self.children[:-1] + [self.w_maps]\n",
    "    \n",
    "    def get_maps_widget(self, widget, event, data):\n",
    "        \n",
    "        self.get_maps_layout() \n",
    "\n",
    "    \n",
    "    def create_map(self):\n",
    "        \n",
    "        self.map_count+=1\n",
    "        \n",
    "        self.maps[self.map_count] = m.SepalMap()\n",
    "        # TODO: Change map height\n",
    "        \n",
    "        self.maps[self.map_count].layout.height = '400px'\n",
    "        \n",
    "        link((self, 'center'), (self.maps[self.map_count], 'center'))\n",
    "        link((self, 'zoom'), (self.maps[self.map_count], 'zoom'))\n",
    "        \n",
    "        return self.maps[self.map_count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "physical-silicon",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp = MultiMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "royal-tackle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo: Create messages\n",
    "# Every map is pointing to a previous one\n",
    "# All polygon must be contained with image footprint\n",
    "# Create reload button\n",
    "# toggle geojson with one button\n",
    "# Set year in top of map\n",
    "# Use multithread to search images\n",
    "# Validate ok message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adjacent-spelling",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c7c57c2825f4b20b7d4f0ed0d9190b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MultiMap(children=[Row(children=[AOI(children=[Layout(children=[FileInput(children=[Btn(children=[Icon(childre…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "[Empty DataFrame\n",
      "Columns: [item_type, id, date]\n",
      "Index: [], Empty DataFrame\n",
      "Columns: [item_type, id, date]\n",
      "Index: [], Empty DataFrame\n",
      "Columns: [item_type, id, date]\n",
      "Index: [],       item_type                       id                date\n",
      "0  PSScene3Band  20200608_144249_49_2277 2020-06-08 14:42:00]\n",
      "4\n",
      "[Empty DataFrame\n",
      "Columns: [item_type, id, date]\n",
      "Index: [], Empty DataFrame\n",
      "Columns: [item_type, id, date]\n",
      "Index: [], Empty DataFrame\n",
      "Columns: [item_type, id, date]\n",
      "Index: [],       item_type                       id                date\n",
      "0  PSScene3Band  20200608_144249_49_2277 2020-06-08 14:42:00]\n",
      "4\n",
      "[Empty DataFrame\n",
      "Columns: [item_type, id, date]\n",
      "Index: [],       item_type                    id                date\n",
      "0  PSScene4Band  20180104_144921_100b 2018-01-04 14:49:00,      item_type                               id                date\n",
      "0  PSOrthoTile  1994218_1841112_2019-01-04_0f44 2019-01-04 15:08:00,       item_type                    id                date\n",
      "0  PSScene3Band  20200104_150847_103b 2020-01-04 15:08:00]\n",
      "4\n",
      "[      item_type                    id                date\n",
      "0  PSScene3Band  20170206_144230_0e30 2017-02-06 14:42:00, Empty DataFrame\n",
      "Columns: [item_type, id, date]\n",
      "Index: [], Empty DataFrame\n",
      "Columns: [item_type, id, date]\n",
      "Index: [], Empty DataFrame\n",
      "Columns: [item_type, id, date]\n",
      "Index: []]\n",
      "4\n",
      "[Empty DataFrame\n",
      "Columns: [item_type, id, date]\n",
      "Index: [],       item_type                    id                date\n",
      "0  PSScene3Band  20180311_145156_1035 2018-03-11 14:51:00, Empty DataFrame\n",
      "Columns: [item_type, id, date]\n",
      "Index: [],       item_type                       id                date\n",
      "0  PSScene3Band  20200321_155637_30_106d 2020-03-21 15:56:00]\n",
      "4\n",
      "[Empty DataFrame\n",
      "Columns: [item_type, id, date]\n",
      "Index: [],       item_type                    id                date\n",
      "0  PSScene4Band  20180408_145325_1012 2018-04-08 14:53:00, Empty DataFrame\n",
      "Columns: [item_type, id, date]\n",
      "Index: [],      item_type                               id                date\n",
      "0  PSOrthoTile  3306786_1841112_2020-04-10_0f1a 2020-04-10 13:57:00]\n",
      "4\n",
      "[Empty DataFrame\n",
      "Columns: [item_type, id, date]\n",
      "Index: [], Empty DataFrame\n",
      "Columns: [item_type, id, date]\n",
      "Index: [],       item_type                    id                date\n",
      "0  PSScene4Band  20190501_145116_1052 2019-05-01 14:51:00,       item_type                       id                date\n",
      "0  PSScene3Band  20200510_143903_71_2257 2020-05-10 14:39:00]\n",
      "4\n",
      "[Empty DataFrame\n",
      "Columns: [item_type, id, date]\n",
      "Index: [], Empty DataFrame\n",
      "Columns: [item_type, id, date]\n",
      "Index: [], Empty DataFrame\n",
      "Columns: [item_type, id, date]\n",
      "Index: [],       item_type                       id                date\n",
      "0  PSScene3Band  20200608_144249_49_2277 2020-06-08 14:42:00]\n",
      "4\n",
      "[      item_type                    id                date\n",
      "0  PSScene3Band  20170716_132025_0c12 2017-07-16 13:20:00, Empty DataFrame\n",
      "Columns: [item_type, id, date]\n",
      "Index: [],       item_type                    id                date\n",
      "0  PSScene4Band  20190706_143959_1050 2019-07-06 14:39:00, Empty DataFrame\n",
      "Columns: [item_type, id, date]\n",
      "Index: []]\n",
      "4\n",
      "[Empty DataFrame\n",
      "Columns: [item_type, id, date]\n",
      "Index: [],      item_type                               id                date\n",
      "0  PSOrthoTile  1623768_1841112_2018-08-11_101b 2018-08-11 14:57:00,       item_type                       id                date\n",
      "0  PSScene3Band  20190821_152120_54_1058 2019-08-21 15:21:00,      item_type                               id                date\n",
      "0  PSOrthoTile  3618772_1841112_2020-08-02_1032 2020-08-02 15:09:00]\n",
      "4\n",
      "[     item_type                              id                date\n",
      "0  PSOrthoTile  736227_1841112_2017-09-05_0d06 2017-09-05 15:28:00, Empty DataFrame\n",
      "Columns: [item_type, id, date]\n",
      "Index: [],      item_type                               id                date\n",
      "0  PSOrthoTile  2648490_1841112_2019-09-03_0f44 2019-09-03 14:32:00,       item_type                       id                date\n",
      "0  PSScene3Band  20200905_144212_14_220b 2020-09-05 14:42:00]\n",
      "5\n",
      "[Empty DataFrame\n",
      "Columns: [item_type, id, date]\n",
      "Index: [],       item_type                    id                date\n",
      "0  PSScene3Band  20180311_145156_1035 2018-03-11 14:51:00, Empty DataFrame\n",
      "Columns: [item_type, id, date]\n",
      "Index: [],       item_type                       id                date\n",
      "0  PSScene3Band  20200321_155637_30_106d 2020-03-21 15:56:00,       item_type                       id                date\n",
      "0  PSScene3Band  20210306_144755_14_2259 2021-03-06 14:47:00]\n",
      "5\n",
      "[     item_type                              id                date\n",
      "0  PSOrthoTile  736227_1841112_2017-09-05_0d06 2017-09-05 15:28:00, Empty DataFrame\n",
      "Columns: [item_type, id, date]\n",
      "Index: [],      item_type                               id                date\n",
      "0  PSOrthoTile  2648490_1841112_2019-09-03_0f44 2019-09-03 14:32:00,       item_type                       id                date\n",
      "0  PSScene3Band  20200905_144212_14_220b 2020-09-05 14:42:00, Empty DataFrame\n",
      "Columns: [item_type, id, date]\n",
      "Index: []]\n"
     ]
    }
   ],
   "source": [
    "mp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
